{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåü ¬°Nuestra Receta Musical con el C√≥digo final para nuestro modelo de recomendaci√≥n sem√°ntica! üåü\n",
    "\n",
    "Imagina que **somos** chefs en una cocina de alta tecnolog√≠a musical, y **hemos** preparado una receta para encontrar las canciones que mejor se adapten a nuestros sentimientos. ¬°Vamos a desglosarlo!\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Preparando los Ingredientes** ü•ëüé∂\n",
    "\n",
    "### Limpieza del Texto: `remove_excessive_repetitions`\n",
    "- **¬øQu√© hace?**  \n",
    "  Elimina repeticiones excesivas en l√≠neas y palabras.  \n",
    "  *Ejemplo: ¬°Nada de \"otra vez, otra vez, otra vez!\"*\n",
    "\n",
    "- **Por qu√© lo usamos:**  \n",
    "  **Nosotros** queremos que cada letra suene √∫nica y sin ruido. Hemos tenido que tirar a la papelera un preprocesamiento del texto excesivo \n",
    "  que hac√≠a que el sabor final fuera bastante agridulce y fuera de nuestra finalidad .\n",
    "\n",
    "---\n",
    "\n",
    "### Traducci√≥n Autom√°tica: `translate_to_english`\n",
    "- **¬øQu√© hace?**  \n",
    "  Detecta el idioma de la consulta y, si no est√° en ingl√©s, la traduce autom√°ticamente. Hemos usado ya muchos scripts del estilo, finalmente aqu√≠ es donde mejor funciona.\n",
    "  Hemos probado adem√°s distintos traductores que busquen algo m√°s all√° pero no mejoraban en exceso o confund√≠an m√°s. As√≠ pues, si sabes ingl√©s escribe en ingl√©s, si no,\n",
    "  a probar mezclita que no funciona nada mal y as√≠ se puede probar el producto local.\n",
    "\n",
    "- **Por qu√© lo usamos:**  \n",
    "  Para que **nuestro** modelo (RoBERTa) pueda entender la consulta a la perfecci√≥n, sin importar el idioma de entrada.  \n",
    "  ![Traducci√≥n](https://img.icons8.com/emoji/48/000000/globe-with-meridians.png)\n",
    "\n",
    "---\n",
    "\n",
    "### Combinaci√≥n de Datos: `combined_text`\n",
    "- **¬øQu√© hace?**  \n",
    "  Une datos clave (nombre de la canci√≥n, artista, letra limpia, g√©neros, playlists, fecha de lanzamiento e idioma) en un solo bloque de texto.\n",
    "\n",
    "- **Por qu√© lo usamos:**  \n",
    "  As√≠, nosotros capturamos la esencia completa de cada canci√≥n en un solo vector informativo.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **El Secreto del Sabor: RoBERTa** üßô‚Äç‚ôÇÔ∏èüîÆ\n",
    "\n",
    "- **¬øQu√© hace?**  \n",
    "  Genera **embeddings** de 1024 dimensiones a partir del texto combinado, convirtiendo las letras en vectores num√©ricos que **nuestro** sistema puede comparar.\n",
    "\n",
    "- **Por qu√© lo usamos:**  \n",
    "  **Nosotros** elegimos a RoBERTa porque es un aut√©ntico maestro del lenguaje. ¬°Captura el contexto y las sutilezas de cada letra como ning√∫n otro!\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **El Turbo Buscador: FAISS** üöÄüîç\n",
    "\n",
    "- **¬øQu√© hace?**  \n",
    "  Indexa los embeddings generados y permite realizar b√∫squedas ultrarr√°pidas entre miles de canciones.\n",
    "\n",
    "- **Por qu√© lo usamos:**  \n",
    "  Imagina tener miles de recetas y necesitar encontrar la ideal en un abrir y cerrar de ojos. **Nosotros** confiamos en FAISS para que cada b√∫squeda sea **r√°pida y precisa**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **El Proceso Completo: De la Consulta al Resultado** üîÑ\n",
    "\n",
    "1. **Preparaci√≥n de Datos:**  \n",
    "   - Leemos el dataset y limpiamos las letras.\n",
    "   - Creamos el \"combo textual\" uniendo toda la informaci√≥n relevante.\n",
    "\n",
    "2. **Generaci√≥n de Embeddings:**  \n",
    "   - RoBERTa transforma el combo en vectores m√°gicos que encapsulan la esencia de cada canci√≥n.\n",
    "\n",
    "3. **Indexaci√≥n con FAISS:**  \n",
    "   - Creamos un √≠ndice para realizar b√∫squedas s√∫per r√°pidas.\n",
    "\n",
    "4. **Consulta del Usuario:**  \n",
    "   - Si escribes algo como \"amor y desamor en la m√∫sica latina\", se traduce (si es necesario) y se convierte en un embedding.\n",
    "   - FAISS busca en el √≠ndice y devuelve los 5 resultados m√°s similares.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Resumen Visual y Din√°mico** üé®‚ú®\n",
    "\n",
    "| **Herramienta**       | **Funci√≥n**                                            | **¬øPor qu√© la elegimos?**                                                 |\n",
    "|-----------------------|--------------------------------------------------------|---------------------------------------------------------------------------|\n",
    "| **RoBERTa**           | Transforma texto en embeddings de 1024 dimensiones     | Es el **maestro** del lenguaje que capta cada matiz de la letra.          |\n",
    "| **FAISS**             | Indexa y busca r√°pidamente entre miles de embeddings    | Es el **turbo buscador** que encuentra resultados en un abrir y cerrar de ojos. |\n",
    "| **Traducci√≥n & Detecci√≥n** | Traduce y detecta el idioma de la consulta           | Para que **nuestro** sistema entienda sin importar el idioma de entrada.    |\n",
    "| **Pandas, NumPy & Pickle** | Manejo y almacenamiento de datos                      | Organizan, transforman y guardan los datos como unos aut√©nticos profesionales. |\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Conclusi√≥n: Nuestra Sinfon√≠a Perfecta** üéµ‚úÖ\n",
    "\n",
    "Hemos combinado:\n",
    "- La **magia de RoBERTa** para entender el alma de cada canci√≥n\n",
    "- La **velocidad de FAISS** para encontrar coincidencias al instante\n",
    "- Y herramientas adicionales que aseguran que cada dato est√© limpio y listo para brillar.\n",
    "\n",
    "**Despu√©s de diversas pruebas esta es la combinaci√≥n que mas nos ha gustado, por supuesto tiene mucho que mejorar\n",
    "un poquito de tiempo extra para la cocci√≥n es lo que nos ha faltado.**\n",
    "\n",
    "¬°As√≠, cada b√∫squeda se convierte en una experiencia musical √∫nica y personalizada!  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\solan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "‚ö° Usando: CUDA\n",
      "‚è≥ Generando nuevos embeddings (vectores de 1024 dimensiones)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d999bbc0be114d5c9580e25d2126efa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 106\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# üìå Generaci√≥n de Embeddings y Creaci√≥n del √çndice FAISS (SIN NORMALIZACI√ìN)\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚è≥ Generando nuevos embeddings (vectores de 1024 dimensiones)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 106\u001b[0m embeddings_list \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcombined_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# üìå Convertir embeddings a un array de NumPy en formato float32\u001b[39;00m\n\u001b[0;32m    109\u001b[0m embeddings_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(embeddings_list, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\solan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:652\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[0;32m    651\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[1;32m--> 652\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    654\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[0;32m    656\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import faiss  # Para b√∫squedas r√°pidas en el √≠ndice de embeddings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer  # Para generar embeddings con RoBERTa\n",
    "import torch  # Para usar la GPU si est√° disponible\n",
    "import os  # Para manejar rutas de archivos\n",
    "from deep_translator import GoogleTranslator  # Para traducci√≥n autom√°tica\n",
    "from langdetect import detect  # Para detectar el idioma de un texto\n",
    "import pickle  # Para guardar los embeddings correctamente\n",
    "\n",
    "# =============================================================================\n",
    "# üìå Funci√≥n para \"sazonar\" las letras y eliminar repeticiones excesivas\n",
    "# =============================================================================\n",
    "def remove_excessive_repetitions(text, max_reps=2):\n",
    "    \"\"\"\n",
    "    Reduce repeticiones excesivas en el texto (l√≠neas y palabras consecutivas).\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # üü¢ Paso 1: Eliminar repeticiones de l√≠neas\n",
    "    lines = text.splitlines()\n",
    "    new_lines = []\n",
    "    count = 1\n",
    "    for i, line in enumerate(lines):\n",
    "        if i > 0 and line.strip() == lines[i - 1].strip():\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 1\n",
    "        if count <= max_reps:\n",
    "            new_lines.append(line)\n",
    "    text_no_line_reps = \"\\n\".join(new_lines)\n",
    "\n",
    "    # üü¢ Paso 2: Eliminar repeticiones de palabras consecutivas\n",
    "    words = text_no_line_reps.split()\n",
    "    new_words = []\n",
    "    count = 1\n",
    "    for i, word in enumerate(words):\n",
    "        if i > 0 and word == words[i - 1]:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 1\n",
    "        if count <= max_reps:\n",
    "            new_words.append(word)\n",
    "\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üìå Funci√≥n para traducir a ingl√©s la consulta del usuario\n",
    "# =============================================================================\n",
    "def translate_to_english(text):\n",
    "    \"\"\"\n",
    "    Traduce la consulta del usuario a ingl√©s si no est√° en ingl√©s.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        detected_lang = detect(text)\n",
    "        if detected_lang != 'en':\n",
    "            translated_text = GoogleTranslator(source='auto', target='en').translate(text)\n",
    "            print(f\"üåç Traducido: '{text}' ‚Üí '{translated_text}'\")\n",
    "            return translated_text\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al detectar idioma: {e}\")\n",
    "        return text\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üìå Rutas de los archivos\n",
    "# =============================================================================\n",
    "file_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\cleaned_songs_data_v2.csv\"\n",
    "faiss_index_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\lyrics_embeddings_faiss_IP.index\"\n",
    "embeddings_file = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\lyrics_embeddings_roberta3.pkl\"\n",
    "\n",
    "# üìå Cargar el dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# üìå Aplicar la funci√≥n para eliminar repeticiones en `processed_lyrics`\n",
    "df['cleaned_lyrics'] = df['processed_lyrics'].apply(lambda x: remove_excessive_repetitions(x, max_reps=2))\n",
    "\n",
    "# üìå Crear un gran \"combo textual\" que contenga toda la informaci√≥n relevante\n",
    "df['combined_text'] = (\n",
    "    df['song_name'].astype(str).fillna('') + \" \" +\n",
    "    df['artist_name'].astype(str).fillna('') + \" \" +\n",
    "    df['cleaned_lyrics'].astype(str).fillna('') + \" \" +\n",
    "    df['combined_genres'].astype(str).fillna('') + \" \" +\n",
    "    df['playlists_names'].astype(str).fillna('') + \" \" +\n",
    "    df['album_release_date'].astype(str).fillna('') + \" \" +\n",
    "    df['language'].astype(str).fillna('')\n",
    ")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üìå Configuraci√≥n del Dispositivo y Carga del Modelo\n",
    "# =============================================================================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"‚ö° Usando: {device.upper()}\")\n",
    "\n",
    "# üìå Inicializar RoBERTa (Modelo para generar embeddings)\n",
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1', device=device)\n",
    "\n",
    "# =============================================================================\n",
    "# üìå Generaci√≥n de Embeddings y Creaci√≥n del √çndice FAISS (SIN NORMALIZACI√ìN)\n",
    "# =============================================================================\n",
    "print(\"‚è≥ Generando nuevos embeddings (vectores de 1024 dimensiones)...\")\n",
    "embeddings_list = model.encode(df['combined_text'].tolist(), batch_size=32, show_progress_bar=True)\n",
    "\n",
    "# üìå Convertir embeddings a un array de NumPy en formato float32\n",
    "embeddings_np = np.array(embeddings_list, dtype=np.float32)\n",
    "d = embeddings_np.shape[1]  # Dimensi√≥n del vector (1024 en este caso)\n",
    "\n",
    "# üìå Crear el √≠ndice FAISS con `IndexFlatIP` (Producto Interno) sin normalizaci√≥n\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(embeddings_np)\n",
    "\n",
    "# üìå Guardar FAISS en archivo con manejo de errores\n",
    "try:\n",
    "    faiss.write_index(index, faiss_index_path)\n",
    "    print(f\"‚úÖ FAISS `IndexFlatIP` guardado en {faiss_index_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al guardar FAISS index: {e}\")\n",
    "\n",
    "# üìå Guardar embeddings en Pickle para futuras consultas (üî• SOLUCIONADO EL ERROR)\n",
    "try:\n",
    "    with open(embeddings_file, \"wb\") as f:\n",
    "        pickle.dump(embeddings_list, f)  # Guardar correctamente como lista\n",
    "    print(f\"‚úÖ Embeddings guardados en {embeddings_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al guardar embeddings en Pickle: {e}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üìå Ejemplo de Consulta y B√∫squeda en FAISS (üî• Ahora con Traducci√≥n)\n",
    "# =============================================================================\n",
    "query = \"amor y desamor en la m√∫sica latina\"\n",
    "query_translated = translate_to_english(query)\n",
    "print(f\"\\n‚è≥ Procesando consulta traducida: '{query_translated}'\")\n",
    "\n",
    "# üìå Generar el embedding de la consulta con RoBERTa\n",
    "query_embedding = model.encode([query_translated], device=device, show_progress_bar=False)\n",
    "query_embedding_np = np.array(query_embedding, dtype=np.float32)\n",
    "\n",
    "# üìå Realizar la b√∫squeda en FAISS (top 5 resultados)\n",
    "k = 5\n",
    "distances, indices = index.search(query_embedding_np, k)\n",
    "\n",
    "# üìå Mostrar resultados\n",
    "if indices.size == 0:\n",
    "    print(\"‚ùå No se encontraron resultados.\")\n",
    "else:\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        sim_score = distances[0][i]\n",
    "        song_info = df.iloc[idx].to_dict()\n",
    "        song_info['similarity'] = sim_score\n",
    "        results.append(song_info)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nüîç Resultados de la b√∫squeda:\")\n",
    "    print(results_df[['song_name', 'artist_name', 'spotify_url', 'similarity']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Usando: CUDA\n",
      "üåç Traducido 'para andar por la playa sola' ‚ûù 'To walk on the beach alone'\n",
      "================================================================================\n",
      "üéµ **Canci√≥n:** nada me obliga\n",
      "üé§ **Artista:** la pestilencia\n",
      "üîó **Spotify:** https://open.spotify.com/track/1ZgffyEDYfzRqr54XQKuF4\n",
      "‚úÖ **Similaridad:** 0.4243\n",
      "\n",
      "üìú **Letra en Ingl√©s:**\n",
      " i would like to be able to go alone without depending on anyone and make my life just go out into the world and see what i find it may be love it may be hate i dont want anything to tie me down nobody i hate passports borders and governments and if my life runs and if my life runs and if my life runs the risk that matters is my solution and if my life runs and if my life runs and if my life runs and if my life runs the risk that matters is my solution and if my life runs and if my life runs and  ...\n",
      "\n",
      "üåç **Traducci√≥n Espa√±ola:**\n",
      " Me gustar√≠a poder ir solo sin depender de nadie y hacer que mi vida salga al mundo y ver lo que me parece que puede ser amor, puede ser odio. gobiernos y si mi vida funciona y si mi vida funciona y si mi vida corre el riesgo que importa es mi soluci√≥n y si mi vida funciona y si mi vida funciona y si mi vida funciona y si mi vida corre el riesgo que importa es mi soluci√≥n y si mi vida funciona y si mi vida funciona y\n",
      "================================================================================ \n",
      "\n",
      "================================================================================\n",
      "üéµ **Canci√≥n:** wandering alone\n",
      "üé§ **Artista:** belle sebastian\n",
      "üîó **Spotify:** https://open.spotify.com/track/2V3FHnQ8EXfgMcrenlFOXF\n",
      "‚úÖ **Similaridad:** 0.4229\n",
      "\n",
      "üìú **Letra en Ingl√©s:**\n",
      " wandering alone on the ridge of the coast lost to the world he had known as a boy he knows his lover lies south in the city passing along and as sleepy as night warm in the woods that conceal him from light he is accustomed to hiding from people taking his time as he crosse the bridge holding the flowers he picked from the ridge walking in shadows to his senorita safe in the dawn he gest under the sheets his senorita a heavenly sweet soul that was put there to save and protect him he knows that  ...\n",
      "\n",
      "üåç **Traducci√≥n Espa√±ola:**\n",
      " Deambulando solo en la cresta de la costa perdi√≥ ante el mundo que hab√≠a conocido como ni√±o, conoce a su amante yace hacia el sur en la ciudad que pasa y tan somnoliento como la noche caliente en el bosque que lo oculta de la luz que est√° acostumbrado a esconderse de la gente taking his time as he crosse the bridge holding the flowers he picked from the ridge walking in shadows to his senorita safe in the dawn he gest under the sheets his senorita a heavenly sweet soul that was put there to save and protect him he knows that\n",
      "================================================================================ \n",
      "\n",
      "================================================================================\n",
      "üéµ **Canci√≥n:** i think ill take a walk\n",
      "üé§ **Artista:** charley pride\n",
      "üîó **Spotify:** https://open.spotify.com/track/4WfRLbBSPR7AH6T4Awn2rd\n",
      "‚úÖ **Similaridad:** 0.4210\n",
      "\n",
      "üìú **Letra en Ingl√©s:**\n",
      " i think ill take a boat and sail the ocean and spend my life just roaming on the sea and kiss the girls from panama to china then shell be sorry she mistreated me i think ill take a walk and think it over cause things are gettin tougher for me here now that someone else has come between us i think ill take a walk and disappear ill think about the way it makes me jealous to see her walking arm in arm with him ill think about the stars up in the heaven and wish that i could be on one of them i thi ...\n",
      "\n",
      "üåç **Traducci√≥n Espa√±ola:**\n",
      " Creo que tomar√© un bote y navegar√© por el oc√©ano y pasar√© mi vida deambulando en el mar y besar√© a las chicas de Panam√° a China, entonces sienten que me maltrat√≥. Creo Yo aqu√≠ ahora que alguien m√°s se ha intervenido entre nosotros, creo que dar√© un paseo y desaparecer√©, pensar√© en la forma en que me pone celoso verla de brazo con √©l, pensar en las estrellas en el cielo y desear√≠a poder estar en uno de ellos\n",
      "================================================================================ \n",
      "\n",
      "================================================================================\n",
      "üéµ **Canci√≥n:** alone\n",
      "üé§ **Artista:** carly simon\n",
      "üîó **Spotify:** https://open.spotify.com/track/2OmvnJ6hbrbCddTqjnGjdD\n",
      "‚úÖ **Similaridad:** 0.4080\n",
      "\n",
      "üìú **Letra en Ingl√©s:**\n",
      " my goin has nothing to do with you im planning a trip all alone and all i want is a room with a view where the sight of the sunset full blown makes me ache with feeling alone and ill think about you there if i do some thinkin and ill care about you there as its love ive know its not to leave you that im goin im just goin to be alone it seems that im hearing those noises again the voices once small now have grown flashbacks keep sending me way back to when the sounds of the waves on the stones ma ...\n",
      "\n",
      "üåç **Traducci√≥n Espa√±ola:**\n",
      " Mi ir no tiene nada que ver contigo, estoy planeando un viaje solo y todo lo que quiero es una habitaci√≥n con una vista en la que la vista de la puesta de sol, me duele al sentirme solo y pensar√© en ti all√≠ si pienso y pienso y pienso y Me preocupar√© por ti all√≠, ya que su amor, s√© que no es de dejarte que voy a ir a estar solo. Parece que estoy escuchando a esos ruidos nuevamente las voces una vez que los peque√±os ahora han crecido los flashbacks siguen envi√°ndome cuando los sonidos de las olas en las piedras ma\n",
      "================================================================================ \n",
      "\n",
      "================================================================================\n",
      "üéµ **Canci√≥n:** gulf shore road\n",
      "üé§ **Artista:** hank williams jr\n",
      "üîó **Spotify:** https://open.spotify.com/track/0mLK2vXwuW8KDZ8XHvztkR\n",
      "‚úÖ **Similaridad:** 0.3898\n",
      "\n",
      "üìú **Letra en Ingl√©s:**\n",
      " verse i want to live on gulf shore road and lighten up my heavy load make all my blues go away looking across pelican bay i want to live on fresh seafood and never be in a bad mood i want to dance with you real slow on moonlight beach on gulf shore road not enough time now in the day for people to ever find their way back to their heart and their homes were too busy talking on the phone my little girl just wants to play in the sand and in the waves and thats all were going do you know life is go ...\n",
      "\n",
      "üåç **Traducci√≥n Espa√±ola:**\n",
      " Verso Quiero vivir en Gulf Shore Road y aligerar mi carga pesada Haga que todos mis blues se vayan mirando a trav√©s de Pelican Bay Quiero vivir con mariscos frescos y nunca estar de mal humor, quiero bailar contigo muy lento en la playa de la luz de la luna En Gulf Shore Road, no hay suficiente tiempo ahora en el d√≠a para que las personas encuentren su camino de regreso a su coraz√≥n y sus casas estaban demasiado ocupadas hablando por tel√©fono, mi ni√±a solo quiere jugar en la arena y en las olas y eso es todo lo Ir, sabes que la vida es ir\n",
      "================================================================================ \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce6aeeb7c2347dda22b9202672be9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Corregir:', layout=Layout(width='80%'), options=(('nada me obliga - la pestilencia‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efc81c3935a428292bcd912174faebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Guardar Errores', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323f0c16ca5446db83b71442fcf8ce32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from deep_translator import GoogleTranslator\n",
    "from langdetect import detect\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import csv  # üîπ Importar correctamente para manejar QUOTE_ALL\n",
    "\n",
    "# üìå Ruta de los archivos\n",
    "embeddings_file_roberta = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\clean_df_embeddings_roberta.pkl\"\n",
    "errores_file = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\errores_canciones.csv\"\n",
    "\n",
    "# üìå Cargar el dataset con los embeddings\n",
    "df = pd.read_pickle(embeddings_file_roberta)\n",
    "\n",
    "# üìå Convertir embeddings a NumPy arrays (para mejor rendimiento)\n",
    "df['embedding'] = df['embedding'].apply(lambda x: np.array(x))\n",
    "\n",
    "# üìå Cargar modelo RoBERTa en GPU si est√° disponible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"‚ö° Usando: {device.upper()}\")\n",
    "\n",
    "model = SentenceTransformer('all-roberta-large-v1', device=device)\n",
    "\n",
    "def translate_to_english(text):\n",
    "    \"\"\"Traduce la frase del usuario a ingl√©s si no est√° en ingl√©s.\"\"\"\n",
    "    detected_lang = detect(text)\n",
    "    if detected_lang != 'en':\n",
    "        translated_text = GoogleTranslator(source='auto', target='en').translate(text)\n",
    "        print(f\"üåç Traducido '{text}' ‚ûù '{translated_text}'\")\n",
    "        return translated_text\n",
    "    return text\n",
    "\n",
    "def translate_to_spanish(text):\n",
    "    \"\"\"Traduce una letra de ingl√©s a espa√±ol.\"\"\"\n",
    "    return GoogleTranslator(source='en', target='es').translate(text) if isinstance(text, str) else \"Traducci√≥n no disponible\"\n",
    "\n",
    "def search_songs(user_query, top_n=5):\n",
    "    \"\"\"Busca canciones en base a una frase del usuario.\"\"\"\n",
    "    translated_query = translate_to_english(user_query)\n",
    "    query_embedding = model.encode(translated_query, convert_to_tensor=True).cpu().numpy()\n",
    "    df['similarity'] = df['embedding'].apply(lambda x: cosine_similarity([x], [query_embedding])[0][0])\n",
    "    top_songs = df.sort_values(by=\"similarity\", ascending=False).head(top_n).copy()\n",
    "    top_songs['translated_lyrics'] = top_songs['processed_lyrics'].apply(lambda x: translate_to_spanish(x[:500]) if isinstance(x, str) else \"Traducci√≥n no disponible\")\n",
    "    return top_songs\n",
    "\n",
    "def mostrar_resultados(resultados):\n",
    "    \"\"\"Muestra las canciones en un formato legible y permite seleccionar para corregir.\"\"\"\n",
    "    \n",
    "    for index, row in resultados.iterrows():\n",
    "        print(\"=\"*80)\n",
    "        print(f\"üéµ **Canci√≥n:** {row['song_name']}\")\n",
    "        print(f\"üé§ **Artista:** {row['artist_name']}\")\n",
    "        print(f\"üîó **Spotify:** {row['spotify_url']}\")\n",
    "        print(f\"‚úÖ **Similaridad:** {row['similarity']:.4f}\")\n",
    "        print(\"\\nüìú **Letra en Ingl√©s:**\\n\", row['processed_lyrics'][:500], \"...\")\n",
    "        print(\"\\nüåç **Traducci√≥n Espa√±ola:**\\n\", row['translated_lyrics'])\n",
    "        print(\"=\"*80, \"\\n\")\n",
    "    \n",
    "    seleccionar_canciones_para_correccion(resultados)\n",
    "\n",
    "# üî¥ Variables globales necesarias para el widget\n",
    "canciones_dropdown = widgets.SelectMultiple(\n",
    "    options=[],\n",
    "    description=\"Corregir:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    "    rows=5\n",
    ")\n",
    "guardar_button = widgets.Button(description=\"Guardar Errores\", button_style=\"danger\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def seleccionar_canciones_para_correccion(resultados):\n",
    "    \"\"\"Permite al usuario seleccionar canciones para corregir y las guarda en errores_canciones.csv\"\"\"\n",
    "    \n",
    "    canciones_dropdown.options = [(f\"{row['song_name']} - {row['artist_name']}\", row[\"recording_id\"]) for _, row in resultados.iterrows()]\n",
    "    display(canciones_dropdown, guardar_button, output)\n",
    "\n",
    "def guardar_errores(b):\n",
    "    \"\"\"Guarda las canciones seleccionadas en errores_canciones.csv\"\"\"\n",
    "    with output:\n",
    "        clear_output()\n",
    "        seleccionados = list(canciones_dropdown.value)\n",
    "        \n",
    "        if not seleccionados:\n",
    "            print(\"‚ö†Ô∏è No has seleccionado ninguna canci√≥n para corregir.\")\n",
    "            return\n",
    "        \n",
    "        # üìå Filtrar las canciones seleccionadas de TODAS las columnas originales\n",
    "        errores_df = df[df[\"recording_id\"].isin(seleccionados)].copy()\n",
    "        \n",
    "        # üîπ **Eliminar saltos de l√≠nea en `processed_lyrics`**\n",
    "        errores_df['processed_lyrics'] = errores_df['processed_lyrics'].apply(lambda x: x.replace(\"\\n\", \" \") if isinstance(x, str) else x)\n",
    "        \n",
    "        # üîπ **Evitar problemas con `embedding`**\n",
    "        errores_df['embedding'] = errores_df['embedding'].apply(lambda x: str(x.tolist()) if isinstance(x, np.ndarray) else x)\n",
    "        \n",
    "        # üìå Guardar en CSV con comillas dobles y sin saltos de l√≠nea extra\n",
    "        try:\n",
    "            df_errores_previos = pd.read_csv(errores_file)\n",
    "            errores_df = pd.concat([df_errores_previos, errores_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            pass  # Si no existe, creamos el archivo desde cero\n",
    "        \n",
    "        errores_df.to_csv(errores_file, index=False, encoding=\"utf-8\", quoting=csv.QUOTE_ALL)\n",
    "\n",
    "        print(f\"‚úÖ Se han guardado {len(seleccionados)} canciones en '{errores_file}' para corregir despu√©s.\")\n",
    "\n",
    "# üìå Conectar el bot√≥n con la funci√≥n\n",
    "guardar_button.on_click(guardar_errores)\n",
    "\n",
    "# üîç Prueba con una consulta\n",
    "user_input = \"para andar por la playa sola\"\n",
    "resultados = search_songs(user_input, top_n=5)\n",
    "\n",
    "# üìå Mostrar resultados y permitir correcci√≥n\n",
    "mostrar_resultados(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Traducido 'canciones que hablen sobre la literatura y los libros' ‚ûù 'songs that talk about literature and books'\n",
      "\n",
      "====================================================================================================\n",
      "üéµ **Canci√≥n:** the farmer and the viper\n",
      "üé§ **Artista:** joshua powell  the great train robbery\n",
      "üîó **Spotify:** https://open.spotify.com/track/3DJWrsP2Wk1OygdnoTMfgs\n",
      "‚úÖ **Similaridad:** 0.5600\n",
      "\n",
      "üìú **Letra Original (Primeros 800 caracteres):**\n",
      " Letra no disponible ...\n",
      "\n",
      "üåç **Traducci√≥n Espa√±ola (Primeros 800 caracteres):**\n",
      " Traducci√≥n no disponible ...\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "üéµ **Canci√≥n:** these foolish things\n",
      "üé§ **Artista:** etta james\n",
      "üîó **Spotify:** https://open.spotify.com/track/1AWrGMHL33h4KtehJNQNcn\n",
      "‚úÖ **Similaridad:** 0.5584\n",
      "\n",
      "üìú **Letra Original (Primeros 800 caracteres):**\n",
      " Letra no disponible ...\n",
      "\n",
      "üåç **Traducci√≥n Espa√±ola (Primeros 800 caracteres):**\n",
      " Traducci√≥n no disponible ...\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "üéµ **Canci√≥n:** cry to me\n",
      "üé§ **Artista:** huey lewis  the news\n",
      "üîó **Spotify:** https://open.spotify.com/track/6yDcWkihD4DebofZLohWPn\n",
      "‚úÖ **Similaridad:** 0.5459\n",
      "\n",
      "üìú **Letra Original (Primeros 800 caracteres):**\n",
      " Letra no disponible ...\n",
      "\n",
      "üåç **Traducci√≥n Espa√±ola (Primeros 800 caracteres):**\n",
      " Traducci√≥n no disponible ...\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "üéµ **Canci√≥n:** bluebirds in the moonlight\n",
      "üé§ **Artista:** glenn miller\n",
      "üîó **Spotify:** https://open.spotify.com/track/7EWXmBsS2eALQtBlMnci8k\n",
      "‚úÖ **Similaridad:** 0.5455\n",
      "\n",
      "üìú **Letra Original (Primeros 800 caracteres):**\n",
      " Letra no disponible ...\n",
      "\n",
      "üåç **Traducci√≥n Espa√±ola (Primeros 800 caracteres):**\n",
      " Traducci√≥n no disponible ...\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "üéµ **Canci√≥n:** anyway the wind blows\n",
      "üé§ **Artista:** jj cale\n",
      "üîó **Spotify:** https://open.spotify.com/track/29uHheFePrbfjma8pTwlp3\n",
      "‚úÖ **Similaridad:** 0.5445\n",
      "\n",
      "üìú **Letra Original (Primeros 800 caracteres):**\n",
      " Letra no disponible ...\n",
      "\n",
      "üåç **Traducci√≥n Espa√±ola (Primeros 800 caracteres):**\n",
      " Traducci√≥n no disponible ...\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# üîç PRUEBA de velocidad con una consulta\n",
    "user_input = \"canciones que hablen sobre la literatura y los libros\"\n",
    "resultados = search_songs(user_input, top_n=5)\n",
    "\n",
    "# üìå Mostrar resultados de forma clara\n",
    "for index, row in resultados.iterrows():\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"üéµ **Canci√≥n:** {row['song_name']}\")\n",
    "    print(f\"üé§ **Artista:** {row['artist_name']}\")\n",
    "    print(f\"üîó **Spotify:** {row['spotify_url']}\")\n",
    "    print(f\"‚úÖ **Similaridad:** {row['similarity']:.4f}\")\n",
    "\n",
    "    # Asegurar que processed_lyrics no sea NaN y convertirlo en string\n",
    "    lyrics = str(row['processed_lyrics']) if pd.notna(row['processed_lyrics']) else \"Letra no disponible\"\n",
    "    translated_lyrics = str(row['translated_lyrics']) if pd.notna(row['translated_lyrics']) else \"Traducci√≥n no disponible\"\n",
    "\n",
    "    print(\"\\nüìú **Letra Original (Primeros 800 caracteres):**\\n\", lyrics[:800], \"...\")\n",
    "    print(\"\\nüåç **Traducci√≥n Espa√±ola (Primeros 800 caracteres):**\\n\", translated_lyrics[:800], \"...\")\n",
    "    print(\"=\"*100)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
