{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📌 Rutas de los archivos\n",
    "final_df_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\final_df.csv\"\n",
    "correcciones_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\errores_canciones_corregidos.csv\"\n",
    "output_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\final_df_corregido.csv\"\n",
    "\n",
    "# 📌 Cargar los datasets\n",
    "df = pd.read_csv(final_df_path)\n",
    "df_correcciones = pd.read_csv(correcciones_path)\n",
    "\n",
    "# 📌 Convertir recording_id a string (por seguridad)\n",
    "df[\"recording_id\"] = df[\"recording_id\"].astype(str)\n",
    "df_correcciones[\"recording_id\"] = df_correcciones[\"recording_id\"].astype(str)\n",
    "\n",
    "# 📌 Verificar que todas las columnas coincidan en ambos archivos\n",
    "if not set(df.columns).issuperset(df_correcciones.columns):\n",
    "    missing_cols = set(df_correcciones.columns) - set(df.columns)\n",
    "    raise ValueError(f\"❌ ERROR: Las siguientes columnas están en el archivo de correcciones pero no en final_df.csv: {missing_cols}\")\n",
    "\n",
    "# 📌 Crear un diccionario con las correcciones {recording_id: {columna: valor}}\n",
    "correcciones_dict = df_correcciones.set_index(\"recording_id\")[[\"spotify_url\", \"processed_lyrics\"]].to_dict(orient=\"index\")\n",
    "\n",
    "# 📌 Validación y actualización segura\n",
    "modificaciones = 0\n",
    "errores = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    rec_id = row[\"recording_id\"]\n",
    "\n",
    "    if rec_id in correcciones_dict:\n",
    "        # 📌 Guardar valores originales antes de actualizar\n",
    "        original_values = row.copy()\n",
    "\n",
    "        # 📌 Aplicar correcciones solo en las columnas permitidas\n",
    "        row[\"spotify_url\"] = correcciones_dict[rec_id][\"spotify_url\"]\n",
    "        row[\"processed_lyrics\"] = correcciones_dict[rec_id][\"processed_lyrics\"]\n",
    "\n",
    "        # 📌 Validar que solo se modificaron las columnas esperadas\n",
    "        for col in df.columns:\n",
    "            if col not in [\"spotify_url\", \"processed_lyrics\"] and row[col] != original_values[col]:\n",
    "                errores.append((rec_id, col))\n",
    "        \n",
    "        # 📌 Si la validación es exitosa, aplicar cambios\n",
    "        if not errores:\n",
    "            df.loc[index] = row  # ✅ Guardar cambios en el DataFrame\n",
    "            modificaciones += 1\n",
    "        else:\n",
    "            print(f\"⚠️ ERROR: Se detectaron cambios en otras columnas para recording_id {rec_id}. No se aplicó la corrección.\")\n",
    "\n",
    "# 📌 Guardar el nuevo dataset corregido\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"✅ {modificaciones} canciones corregidas con éxito. Archivo guardado en:\\n{output_path}\")\n",
    "\n",
    "if errores:\n",
    "    print(f\"❌ {len(errores)} errores detectados donde otras columnas cambiaron accidentalmente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📌 Rutas de los archivos\n",
    "original_file = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\final_df.csv\"\n",
    "correcciones_file = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\errores_canciones_corregidos.csv\"\n",
    "output_file = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\final_df_actualizado.csv\"\n",
    "backup_file = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\final_df_backup.csv\"\n",
    "\n",
    "# 📌 Cargar datasets\n",
    "df_original = pd.read_csv(original_file)\n",
    "df_correcciones = pd.read_csv(correcciones_file)\n",
    "\n",
    "# 📌 Copia de seguridad antes de modificar el dataset original\n",
    "df_original.to_csv(backup_file, index=False)\n",
    "print(f\"📌 Copia de seguridad creada en {backup_file}\")\n",
    "\n",
    "# 📌 Fusionar datasets basados en recording_id (sin duplicar)\n",
    "df_actualizado = df_original.merge(df_correcciones, on=\"recording_id\", how=\"left\", suffixes=(\"\", \"_corregido\"))\n",
    "\n",
    "# 📌 Aplicar correcciones solo en las filas con valores corregidos\n",
    "for col in [\"spotify_url\", \"processed_lyrics\"]:  # 🛠️ Puedes añadir más columnas si necesitas\n",
    "    df_actualizado[col] = df_actualizado[col + \"_corregido\"].combine_first(df_actualizado[col])\n",
    "\n",
    "# 📌 Eliminar columnas temporales de fusión\n",
    "df_actualizado.drop(columns=[col + \"_corregido\" for col in [\"spotify_url\", \"processed_lyrics\"]], inplace=True)\n",
    "\n",
    "# 📌 Guardar dataset actualizado\n",
    "df_actualizado.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Dataset actualizado guardado en {output_file}\")\n",
    "print(\"🚀 No hay duplicados, solo se reemplazaron datos corregidos.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
