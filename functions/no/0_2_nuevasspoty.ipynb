{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "# Análisis y Limpieza de Datos de Spotify\n",
    "\n",
    "Este cuaderno de Jupyter documenta el proceso de análisis y limpieza de un conjunto de datos de canciones de Spotify. A continuación se describen los pasos realizados y el propósito de cada uno.\n",
    "\n",
    "## 1. Cargar Datos Iniciales\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\final_url6.csv\"\n",
    "df_clean = pd.read_csv(file_path, low_memory=False)\n",
    "```\n",
    "\n",
    "Se carga el archivo CSV `final_url6.csv` en un DataFrame de pandas para su posterior análisis.\n",
    "\n",
    "## 2. Selección y Análisis de Columnas de Interés\n",
    "\n",
    "```python\n",
    "# Crear un nuevo dataframe con las columnas de interés\n",
    "columns_to_check = ['album_name', 'popularity', 'album_release_date', 'spotify_url', 'duration_ms']\n",
    "df_no_url = df_clean[columns_to_check]\n",
    "\n",
    "# Contar nulos en cada columna\n",
    "null_counts = df_no_url.isnull().sum()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Número de nulos por columna:\")\n",
    "print(null_counts)\n",
    "\n",
    "# Verificar si todas las columnas tienen el mismo número de nulos\n",
    "same_nulls = null_counts.nunique() == 1\n",
    "print(f\"\\n¿Tienen todas las columnas el mismo número de nulos? {'Sí' if same_nulls else 'No'}\")\n",
    "print(f\"\\nParece igualmente que es caso de urls no encontradas, voy a pasarlas de nuevo a buscar urls por si hubiera suerte\")\n",
    "```\n",
    "\n",
    "Se seleccionan las columnas de interés y se cuenta el número de valores nulos en cada una de ellas. Además, se verifica si todas las columnas tienen el mismo número de nulos.\n",
    "\n",
    "## 3. Filtrado de Filas con Valores Nulos\n",
    "\n",
    "```python\n",
    "# Crear un dataframe con filas que tienen valores nulos en 'spotify_url'\n",
    "df_no_url = df_clean[df_clean[['spotify_url', 'duration_ms']].isnull().any(axis=1)]\n",
    "\n",
    "# Verificar las primeras filas del nuevo dataframe\n",
    "print(df_no_url.head())\n",
    "\n",
    "# Guardar el nuevo dataframe como un archivo CSV\n",
    "df_no_url.to_csv('df_no_url.csv', index=False)\n",
    "print(\"El archivo `df_no_url.csv` ha sido guardado exitosamente.\")\n",
    "```\n",
    "\n",
    "Se crea un nuevo DataFrame que contiene solo las filas con valores nulos en las columnas `spotify_url` o `duration_ms`. Este DataFrame se guarda en un archivo CSV para su posterior análisis.\n",
    "\n",
    "## 4. Actualización de Datos con Nuevas URLs\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar los archivos\n",
    "final_idiomas_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\final_url5.csv\"\n",
    "df_new_url_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\df_url5.csv\"\n",
    "output_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\final_url6.csv\"\n",
    "\n",
    "final_idiomas = pd.read_csv(final_idiomas_path)\n",
    "df_new_url = pd.read_csv(df_new_url_path)\n",
    "\n",
    "# Columnas que queremos actualizar\n",
    "columns_to_update = ['album_name', 'popularity', 'album_release_date', 'spotify_url', 'duration_ms']\n",
    "\n",
    "# Fusionar los datasets por `recording_id`\n",
    "df_merged = final_idiomas.merge(df_new_url[['recording_id'] + columns_to_update], \n",
    "                                on='recording_id', how='left', suffixes=('', '_new'))\n",
    "\n",
    "# Reemplazar solo los valores nulos en `final_idiomas`\n",
    "for col in columns_to_update:\n",
    "    df_merged[col] = df_merged[col].combine_first(df_merged[col + '_new'])\n",
    "    df_merged.drop(columns=[col + '_new'], inplace=True)  # Eliminar columnas auxiliares\n",
    "\n",
    "# Guardar el DataFrame actualizado\n",
    "df_merged.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Archivo actualizado guardado en: {output_path}\")\n",
    "```\n",
    "\n",
    "Se cargan dos archivos CSV y se fusionan para actualizar las columnas de interés con nuevas URLs. Los valores nulos en el DataFrame original se reemplazan con los valores correspondientes del nuevo DataFrame.\n",
    "\n",
    "## 5. Verificación de Datos Actualizados\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(output_path, low_memory=False)\n",
    "```\n",
    "\n",
    "Se carga el archivo CSV actualizado para verificar los cambios realizados.\n",
    "\n",
    "## 6. Análisis de Valores Nulos\n",
    "\n",
    "```python\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "```\n",
    "\n",
    "Se cuentan y muestran los valores nulos por columna en el DataFrame actualizado.\n",
    "\n",
    "```python\n",
    "null_values = df.isnull().sum()\n",
    "null_values = null_values[null_values > 0]  # Filtrar solo las columnas con nulos\n",
    "print(null_values.sort_values(ascending=False))  # Ordenar de mayor a menor\n",
    "```\n",
    "\n",
    "Se filtran y ordenan las columnas que aún contienen valores nulos.\n",
    "\n",
    "## 7. Análisis de Filas Duplicadas\n",
    "\n",
    "```python\n",
    "print(\"\\nNúmero total de filas duplicadas:\", df.duplicated().sum())\n",
    "```\n",
    "\n",
    "Se cuenta y muestra el número total de filas duplicadas en el DataFrame.\n",
    "\n",
    "Este cuaderno proporciona un flujo de trabajo completo para la limpieza y actualización de datos de canciones de Spotify, asegurando que los datos estén lo más completos y precisos posible.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\final_url6.csv\"\n",
    "df_clean = pd.read_csv(file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de nulos por columna:\n",
      "album_name             482\n",
      "popularity             464\n",
      "album_release_date     464\n",
      "spotify_url            463\n",
      "duration_ms           6115\n",
      "dtype: int64\n",
      "\n",
      "¿Tienen todas las columnas el mismo número de nulos? No\n",
      "\n",
      "Parece igualmente que es caso de urls no encontradas, voy a pasarlas de nuevo a buscar urls por si hubiera suerte\n"
     ]
    }
   ],
   "source": [
    "# Crear un nuevo dataframe con las columnas de interés\n",
    "columns_to_check = ['album_name', 'popularity', 'album_release_date', 'spotify_url', 'duration_ms']\n",
    "df_no_url = df_clean[columns_to_check]\n",
    "\n",
    "# Contar nulos en cada columna\n",
    "null_counts = df_no_url.isnull().sum()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Número de nulos por columna:\")\n",
    "print(null_counts)\n",
    "\n",
    "# Verificar si todas las columnas tienen el mismo número de nulos\n",
    "same_nulls = null_counts.nunique() == 1\n",
    "print(f\"\\n¿Tienen todas las columnas el mismo número de nulos? {'Sí' if same_nulls else 'No'}\")\n",
    "print(f\"\\nParece igualmente que es caso de urls no encontradas, voy a pasarlas de nuevo a buscar urls por si hubiera suerte\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         artist_name              song_name  \\\n",
      "30      kina grannis               together   \n",
      "53   maximum balloon             the lesson   \n",
      "59       i am arrows                    nun   \n",
      "92    kill the noise    perfect combination   \n",
      "108        los lobos  the lady and the rose   \n",
      "\n",
      "                             recording_id  danceable  not_danceable   male  \\\n",
      "30   02352d4b-c907-4724-b515-c9c8a0849200      0.164          0.836  0.999   \n",
      "53   037d34c3-b68d-4649-ad93-41f7dea68d13      0.934          0.066  0.653   \n",
      "59   03c73e10-435b-4770-b7ca-93dc78ffc24b      0.991          0.009  0.974   \n",
      "92   0665c0ec-3dfe-4312-845f-bd863cd03080      1.000          0.000  0.990   \n",
      "108  075e85aa-979a-4280-ae69-6eb66c2603e8      0.930          0.070  0.029   \n",
      "\n",
      "     female  timbre_bright  timbre_dark  tonal  ...  album_release_date  \\\n",
      "30    0.001          0.848        0.152  0.051  ...          2001-07-24   \n",
      "53    0.347          0.228        0.772  0.069  ...          2019-04-19   \n",
      "59    0.026          0.471        0.529  0.311  ...          2018-03-09   \n",
      "92    0.010          0.430        0.570  0.027  ...          2018-06-27   \n",
      "108   0.971          0.642        0.358  0.820  ...          2018-06-27   \n",
      "\n",
      "     duration_ms  popularity  language  views  \\\n",
      "30           NaN        25.0        en  424.0   \n",
      "53           NaN        39.0        en    NaN   \n",
      "59           NaN        18.0        en    NaN   \n",
      "92           NaN        10.0        en    NaN   \n",
      "108          NaN        16.0        en    NaN   \n",
      "\n",
      "                                track_uri                      playlist_ids  \\\n",
      "30   spotify:track:5hyCgN54DzKlKF8oEliaPO                  [169388, 282231]   \n",
      "53   spotify:track:76ZLQRfI5r49Olm5ZEKm5V                          [370195]   \n",
      "59   spotify:track:3OQJMvLv3izdAemg4BcCSX                           [38861]   \n",
      "92   spotify:track:08gggEGEiUm15pUg5GAyIC  [276205, 301775, 404744, 515607]   \n",
      "108  spotify:track:54o4X0EakAEyZ5QxXUfWr4                          [344383]   \n",
      "\n",
      "            positions                              playlists_names  \\\n",
      "30           [15, 43]                   ['Island jams', 'Reggae ']   \n",
      "53              [115]                                    ['SHOOT']   \n",
      "59                [6]                                   ['random']   \n",
      "92   [41, 40, 26, 38]  ['Programming', 'Dank', 'BaSs', 'Dubstep ']   \n",
      "108             [123]                                   ['Friday']   \n",
      "\n",
      "                                       combined_genres  \n",
      "30   ['Pop'] acoustic female vocalists singer songw...  \n",
      "53   ['Pop'] electronic, synthpop, indie, pop, TV o...  \n",
      "59   ['Rock'] indie, indie pop, seen live, british,...  \n",
      "92   dubstep, electronic, electro, electro house, H...  \n",
      "108  ['Latin; Rock'] latin, rock, tex-mex, spanish,...  \n",
      "\n",
      "[5 rows x 87 columns]\n",
      "El archivo `df_no_url.csv` ha sido guardado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Crear un dataframe con filas que tienen valores nulos en 'spotify_url'\n",
    "df_no_url = df_clean[df_clean[['spotify_url', 'duration_ms']].isnull().any(axis=1)]\n",
    "\n",
    "# Verificar las primeras filas del nuevo dataframe\n",
    "print(df_no_url.head())\n",
    "\n",
    "# Guardar el nuevo dataframe como un archivo CSV\n",
    "df_no_url.to_csv('df_no_url.csv', index=False)\n",
    "print(\"El archivo `df_no_url.csv` ha sido guardado exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pasarlas por spotify spoty nuevas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo actualizado guardado en: C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\final_url6.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los archivos\n",
    "final_idiomas_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\final_url5.csv\"\n",
    "df_new_url_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\src\\df_url5.csv\"\n",
    "output_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\final_url6.csv\"\n",
    "\n",
    "final_idiomas = pd.read_csv(final_idiomas_path)\n",
    "df_new_url = pd.read_csv(df_new_url_path)\n",
    "\n",
    "# Columnas que queremos actualizar\n",
    "columns_to_update = ['album_name', 'popularity', 'album_release_date', 'spotify_url', 'duration_ms']\n",
    "\n",
    "# Fusionar los datasets por `recording_id`\n",
    "df_merged = final_idiomas.merge(df_new_url[['recording_id'] + columns_to_update], \n",
    "                                on='recording_id', how='left', suffixes=('', '_new'))\n",
    "\n",
    "# Reemplazar solo los valores nulos en `final_idiomas`\n",
    "for col in columns_to_update:\n",
    "    df_merged[col] = df_merged[col].combine_first(df_merged[col + '_new'])\n",
    "    df_merged.drop(columns=[col + '_new'], inplace=True)  # Eliminar columnas auxiliares\n",
    "\n",
    "# Guardar el DataFrame actualizado\n",
    "df_merged.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Archivo actualizado guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      "artist_name            0\n",
      "song_name              2\n",
      "recording_id           0\n",
      "danceable              0\n",
      "not_danceable          0\n",
      "                   ...  \n",
      "track_uri          63072\n",
      "playlist_ids       63084\n",
      "positions          63084\n",
      "playlists_names    63084\n",
      "combined_genres     1174\n",
      "Length: 87, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores nulos por columna:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playlist_ids          63084\n",
      "positions             63084\n",
      "playlists_names       63084\n",
      "track_uri             63072\n",
      "views                 43204\n",
      "language              29082\n",
      "lyrics                 5235\n",
      "duration_ms            4451\n",
      "combined_genres        1174\n",
      "album_name              480\n",
      "album_release_date      462\n",
      "popularity              462\n",
      "spotify_url             461\n",
      "song_name                 2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_values = df.isnull().sum()\n",
    "null_values = null_values[null_values > 0]  # Filtrar solo las columnas con nulos\n",
    "print(null_values.sort_values(ascending=False))  # Ordenar de mayor a menor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número total de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNúmero total de filas duplicadas:\", df.duplicated().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
