{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Cargando el dataset...\n",
      "✅ Dataset cargado correctamente.\n",
      "🎯 Filas pendientes de procesar: 20352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:   5%|▍         | 1010/20352 [00:21<1:34:38,  3.41 canción/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (1000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  10%|▉         | 2009/20352 [00:42<1:12:10,  4.24 canción/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (2000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  15%|█▍        | 3025/20352 [01:02<51:02,  5.66 canción/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (3000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  20%|█▉        | 4011/20352 [01:21<46:36,  5.84 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (4000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  24%|██▍       | 4985/20352 [01:40<01:42, 150.19 canción/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (5000 canciones procesadas).\n",
      "⏸️ Pausa breve tras 5000 filas procesadas para evitar sobrecarga...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  30%|██▉       | 6013/20352 [02:13<59:38,  4.01 canción/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (6000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  34%|███▍      | 7017/20352 [02:33<40:36,  5.47 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (7000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  39%|███▉      | 8016/20352 [02:52<34:09,  6.02 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (8000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  44%|████▍     | 9008/20352 [03:11<43:54,  4.31 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (9000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  49%|████▉     | 9998/20352 [03:30<01:22, 125.78 canción/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (10000 canciones procesadas).\n",
      "⏸️ Pausa breve tras 10000 filas procesadas para evitar sobrecarga...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  54%|█████▍    | 11029/20352 [04:00<21:31,  7.22 canción/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (11000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  59%|█████▉    | 12013/20352 [04:20<25:04,  5.54 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (12000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  64%|██████▍   | 13019/20352 [04:39<20:53,  5.85 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (13000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  69%|██████▉   | 14011/20352 [04:58<25:11,  4.20 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (14000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  74%|███████▎  | 14995/20352 [05:05<00:35, 150.96 canción/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (15000 canciones procesadas).\n",
      "⏸️ Pausa breve tras 15000 filas procesadas para evitar sobrecarga...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  79%|███████▊  | 16015/20352 [05:47<12:23,  5.83 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (16000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  84%|████████▎ | 17011/20352 [06:06<13:53,  4.01 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (17000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  89%|████████▊ | 18043/20352 [06:26<04:22,  8.79 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (18000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  93%|█████████▎| 19011/20352 [06:46<06:04,  3.68 canción/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (19000 canciones procesadas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma:  98%|█████████▊| 19993/20352 [06:53<00:02, 123.76 canción/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Progreso guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv (20000 canciones procesadas).\n",
      "⏸️ Pausa breve tras 20000 filas procesadas para evitar sobrecarga...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Detectando idioma: 100%|██████████| 20352/20352 [07:18<00:00, 46.36 canción/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo final guardado en C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\df_lyrics_faltan_traduc_idioma_faltaspoty.csv\n",
      "🗑️ Archivo temporal eliminado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, DetectorFactory\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# 📌 Configurar aleatoriedad para reproducibilidad\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# 📌 Rutas del dataset\n",
    "input_file = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\df_lyrics_faltan_traduc_actualizado.csv\"\n",
    "output_file = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\df_lyrics_faltan_traduc_idioma_faltaspoty.csv\"\n",
    "temp_file = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\temp_language_detection.csv\"\n",
    "\n",
    "# 📌 Función para dividir letras largas en fragmentos\n",
    "def split_text(text, chunk_size=500):\n",
    "    \"\"\"Divide un texto largo en fragmentos más pequeños para mejorar la detección de idioma.\"\"\"\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# 📌 Función mejorada para detectar idioma\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        if not isinstance(text, str) or len(text.strip()) < 10:  # Ignorar textos cortos\n",
    "            return None\n",
    "        \n",
    "        # 📌 Si el texto es largo, dividir en fragmentos y detectar idioma en cada uno\n",
    "        fragments = split_text(text, chunk_size=500)\n",
    "        detected_languages = [detect(fragment) for fragment in fragments]\n",
    "        \n",
    "        # 📌 Determinar el idioma más frecuente\n",
    "        most_common_lang = Counter(detected_languages).most_common(1)[0][0]\n",
    "        return most_common_lang\n",
    "    \n",
    "    except Exception:\n",
    "        return None  # Si hay error, devolver None en lugar de fallar\n",
    "\n",
    "# 📌 Función para detectar idioma y guardar progreso\n",
    "def add_language_column(input_file, output_file, save_interval=1000, pause_interval=5000):\n",
    "    try:\n",
    "        # 📌 Cargar dataset\n",
    "        print(\"🔄 Cargando el dataset...\")\n",
    "        df = pd.read_csv(input_file, encoding=\"utf-8\", low_memory=False)\n",
    "        print(\"✅ Dataset cargado correctamente.\")\n",
    "\n",
    "        # 📌 Verificar si ya existe la columna 'language'\n",
    "        if \"language\" not in df.columns:\n",
    "            df[\"language\"] = None\n",
    "\n",
    "        # 📌 Cargar progreso si existe un archivo temporal\n",
    "        if os.path.exists(temp_file):\n",
    "            print(\"🔄 Archivo temporal encontrado. Cargando progreso...\")\n",
    "            df_temp = pd.read_csv(temp_file, encoding=\"utf-8\")\n",
    "            df.update(df_temp)  # Actualizar el dataset principal\n",
    "            print(\"✅ Progreso recuperado.\")\n",
    "\n",
    "        # 📌 Filtrar filas sin idioma detectado\n",
    "        missing_lang_indices = df[df[\"language\"].isna() & df[\"lyrics\"].notna()].index.tolist()\n",
    "        print(f\"🎯 Filas pendientes de procesar: {len(missing_lang_indices)}\")\n",
    "\n",
    "        if not missing_lang_indices:\n",
    "            print(\"✅ No hay filas pendientes. Nada que procesar.\")\n",
    "            return\n",
    "\n",
    "        # 📌 Procesar canciones sin idioma detectado con barra de progreso\n",
    "        for i, idx in enumerate(tqdm(missing_lang_indices, desc=\"🔍 Detectando idioma\", unit=\" canción\")):\n",
    "            df.at[idx, \"language\"] = detect_language(df.at[idx, \"lyrics\"])\n",
    "\n",
    "            # 📌 Guardar progreso cada `save_interval` filas\n",
    "            if (i + 1) % save_interval == 0:\n",
    "                df.to_csv(temp_file, index=False, encoding=\"utf-8\")\n",
    "                print(f\"💾 Progreso guardado en {temp_file} ({i + 1} canciones procesadas).\")\n",
    "\n",
    "            # 📌 Pausar cada `pause_interval` filas para evitar sobrecarga\n",
    "            if (i + 1) % pause_interval == 0:\n",
    "                print(f\"⏸️ Pausa breve tras {i + 1} filas procesadas para evitar sobrecarga...\")\n",
    "                time.sleep(10)  # Espera 10 segundos\n",
    "\n",
    "        # 📌 Guardar archivo final\n",
    "        df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "        print(f\"✅ Archivo final guardado en {output_file}\")\n",
    "\n",
    "        # 📌 Eliminar el archivo temporal después de completar la detección\n",
    "        if os.path.exists(temp_file):\n",
    "            os.remove(temp_file)\n",
    "            print(\"🗑️ Archivo temporal eliminado.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ El archivo {input_file} no se encontró. Verifica la ruta.\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Se produjo un error inesperado: {e}\")\n",
    "\n",
    "# 📌 Ejecutar detección\n",
    "if __name__ == \"__main__\":\n",
    "    add_language_column(input_file, output_file, save_interval=1000, pause_interval=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'it', 'es', 'ko', 'de', 'pt', 'fr', nan, 'tr', 'da', 'nl',\n",
       "       'so', 'ja', 'ca', 'sv', 'fi', 'no', 'cy', 'lb', 'ru', 'et', 'af',\n",
       "       'id', 'la', 'pl', 'sl', 'ga', 'ro', 'tl', 'zh', 'sk', 'lv', 'hi',\n",
       "       'is', 'haw', 'ht', 'sw', 'hr', 'ig', 'xh', 'bs', 'hu', 'ha', 'el',\n",
       "       'fy', 'fil', 'mi', 'fa', 'mt', 'ne', 'bg', 'co', 'mk', 'gd', 'sq',\n",
       "       'cs', 'ar', 'ms', 'yo', 'ceb', 'vi', 'lt', 'ku', 'su', 'eo', 'st',\n",
       "       'eu', 'ta', 'ny', 'jv', 'sn', 'gl', 'zu', 'mg', 'he', 'sd'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores unicos en la columna language\n",
    "df_language = pd.read_csv(r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\df_lyrics_faltan_traduc_idioma_2_faltaspoty.csv\")\n",
    "df_language[\"language\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con '❓': 0\n"
     ]
    }
   ],
   "source": [
    "# 📌 Contar filas con `❓` en `language`\n",
    "missing_lang_rows = df_language [df_language [\"language\"] == \"❓\"]\n",
    "print(f\"Filas con '❓': {len(missing_lang_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Column  Missing Values  Missing Percentage\n",
      "translated_lyrics    translated_lyrics          142842           90.514603\n",
      "playlists_names        playlists_names           63084           39.974400\n",
      "positions                    positions           63084           39.974400\n",
      "playlist_ids              playlist_ids           63084           39.974400\n",
      "track_uri                    track_uri           63072           39.966796\n",
      "views                            views           43204           27.377052\n",
      "duration_ms                duration_ms            4451            2.820462\n",
      "lyrics                          lyrics            2711            1.717878\n",
      "language                      language            2705            1.714076\n",
      "combined_genres        combined_genres            1174            0.743928\n",
      "album_name                  album_name             480            0.304161\n",
      "album_release_date  album_release_date             462            0.292755\n",
      "popularity                  popularity             462            0.292755\n",
      "spotify_url                spotify_url             461            0.292122\n",
      "song_name                    song_name               2            0.001267\n"
     ]
    }
   ],
   "source": [
    "# Análisis de valores nulos\n",
    "missing_values = df_language.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df_language)) * 100\n",
    "\n",
    "# Crear un resumen de los nulos\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df_language.columns,\n",
    "    'Missing Values': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "}).sort_values(by='Missing Percentage', ascending=False)\n",
    "\n",
    "# Mostrar columnas con nulos\n",
    "print(missing_summary[missing_summary['Missing Percentage'] > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name               0\n",
       "song_name                 2\n",
       "recording_id              0\n",
       "danceable                 0\n",
       "not_danceable             0\n",
       "                      ...  \n",
       "playlist_ids          63084\n",
       "positions             63084\n",
       "playlists_names       63084\n",
       "combined_genres        1174\n",
       "translated_lyrics    142842\n",
       "Length: 88, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Filas a re-detectar: 2703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solan\\AppData\\Local\\Temp\\ipykernel_11924\\3532347958.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"language\"].replace(\"❓\", pd.NA, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo actualizado sin '❓' en `language`: C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\df_lyrics_faltan_traduc_idioma_2_faltaspoty.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, DetectorFactory\n",
    "from collections import Counter\n",
    "\n",
    "# 📌 Configurar aleatoriedad para reproducibilidad\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# 📌 Rutas del dataset\n",
    "file_path = r\"C:\\Users\\solan\\Downloads\\get_data_from_songs\\data\\df_lyrics_faltan_traduc_idioma_2_faltaspoty.csv\"\n",
    "\n",
    "# 📌 Cargar dataset\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "# 📌 Función para dividir letras largas\n",
    "def split_text(text, chunk_size=500):\n",
    "    \"\"\"Divide un texto largo en fragmentos más pequeños para mejorar la detección de idioma.\"\"\"\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# 📌 Función mejorada para detectar idioma\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        if not isinstance(text, str) or len(text.strip()) < 10:\n",
    "            return None  # Ignorar textos cortos\n",
    "\n",
    "        # 📌 Si el texto es largo, dividir en fragmentos y detectar idioma en cada uno\n",
    "        fragments = split_text(text, chunk_size=500)\n",
    "        detected_languages = [detect(fragment) for fragment in fragments]\n",
    "\n",
    "        # 📌 Determinar el idioma más frecuente\n",
    "        most_common_lang = Counter(detected_languages).most_common(1)[0][0]\n",
    "        return most_common_lang\n",
    "\n",
    "    except Exception:\n",
    "        return None  # Si hay error, devolver None\n",
    "\n",
    "# 📌 Filtrar solo las filas con `❓`\n",
    "rows_with_unknown = df[\"language\"] == \"❓\"\n",
    "print(f\"🔍 Filas a re-detectar: {rows_with_unknown.sum()}\")\n",
    "\n",
    "# 📌 Aplicar detección solo a las letras con `❓`\n",
    "df.loc[rows_with_unknown, \"language\"] = df.loc[rows_with_unknown, \"lyrics\"].apply(detect_language)\n",
    "\n",
    "# 📌 Reemplazar los `❓` restantes con `NaN`\n",
    "df[\"language\"].replace(\"❓\", pd.NA, inplace=True)\n",
    "\n",
    "# 📌 Guardar el archivo corregido\n",
    "df.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Archivo actualizado sin '❓' en `language`: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
